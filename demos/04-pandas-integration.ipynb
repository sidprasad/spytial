{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7a4c4e",
   "metadata": {},
   "source": [
    "# sPyTial for Pandas: Structural Understanding of DataFrames\n",
    "\n",
    "**Why sPyTial beats traditional pandas visualization approaches**\n",
    "\n",
    "Traditional pandas visualization focuses on *statistical* patterns in your data. sPyTial focuses on the *structural* relationships - showing how your DataFrame is organized, how columns relate to each other, and revealing hidden data architecture.\n",
    "\n",
    "## The Problem with Traditional Approaches\n",
    "\n",
    "When working with pandas DataFrames, most visualizations show you:\n",
    "- **What the data looks like** (histograms, scatter plots)\n",
    "- **Statistical relationships** (correlations, distributions)\n",
    "\n",
    "But they don't show you:\n",
    "- **How your data is structured** \n",
    "- **Relationships between DataFrame components**\n",
    "- **Data architecture patterns**\n",
    "\n",
    "sPyTial fills this gap by treating DataFrames as spatial objects with meaningful relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf56e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(str(Path().resolve().parent))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from spytial import diagram, orientation, group, attribute, atomColor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b09393",
   "metadata": {},
   "source": [
    "## Demo 1: DataFrame Structure Visualization\n",
    "\n",
    "Let's start with a real-world dataset and compare traditional vs sPyTial approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic employee dataset\n",
    "np.random.seed(42)\n",
    "n_employees = 100\n",
    "\n",
    "departments = ['Engineering', 'Sales', 'Marketing', 'HR', 'Finance']\n",
    "levels = ['Junior', 'Mid', 'Senior', 'Lead', 'Director']\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'employee_id': range(1001, 1001 + n_employees),\n",
    "    'name': [f'Employee_{i}' for i in range(n_employees)],\n",
    "    'department': np.random.choice(departments, n_employees),\n",
    "    'level': np.random.choice(levels, n_employees),\n",
    "    'salary': np.random.normal(75000, 25000, n_employees).astype(int),\n",
    "    'years_experience': np.random.randint(0, 20, n_employees),\n",
    "    'performance_score': np.random.uniform(1, 5, n_employees).round(2)\n",
    "})\n",
    "\n",
    "# Add some realistic salary adjustments based on level\n",
    "level_multipliers = {'Junior': 0.8, 'Mid': 1.0, 'Senior': 1.3, 'Lead': 1.6, 'Director': 2.0}\n",
    "df['salary'] = df.apply(lambda row: int(row['salary'] * level_multipliers[row['level']]), axis=1)\n",
    "\n",
    "print(\"Traditional pandas DataFrame view:\")\n",
    "print(df.head())\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2327b0a",
   "metadata": {},
   "source": [
    "### Traditional Visualization: Shows Data Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aacc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional approach: Statistical visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "fig.suptitle('Traditional Pandas Visualization: Data Patterns', fontsize=16)\n",
    "\n",
    "# Salary distribution\n",
    "df['salary'].hist(bins=20, ax=axes[0,0])\n",
    "axes[0,0].set_title('Salary Distribution')\n",
    "axes[0,0].set_xlabel('Salary')\n",
    "\n",
    "# Department counts\n",
    "df['department'].value_counts().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Employees by Department')\n",
    "axes[0,1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Salary vs Experience\n",
    "axes[1,0].scatter(df['years_experience'], df['salary'], alpha=0.6)\n",
    "axes[1,0].set_title('Salary vs Experience')\n",
    "axes[1,0].set_xlabel('Years Experience')\n",
    "axes[1,0].set_ylabel('Salary')\n",
    "\n",
    "# Performance by Level\n",
    "df.boxplot(column='performance_score', by='level', ax=axes[1,1])\n",
    "axes[1,1].set_title('Performance by Level')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üëÜ Traditional approach tells us WHAT the data looks like\")\n",
    "print(\"But it doesn't show us HOW the data is structured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bde82f",
   "metadata": {},
   "source": [
    "### sPyTial Approach: Shows Data Structure\n",
    "\n",
    "Now let's use sPyTial to visualize the *structural* aspects of our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sPyTial DataFrame Visualization: Structure & Relationships\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# sPyTial shows the DataFrame as a structured object\n",
    "diagram(df, method=\"inline\")\n",
    "\n",
    "print(\"\\nüëÜ sPyTial shows HOW your DataFrame is organized:\")\n",
    "print(\"- The spatial arrangement of columns\")\n",
    "print(\"- Relationships between DataFrame components\")\n",
    "print(\"- The actual structure of your data object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2272576f",
   "metadata": {},
   "source": [
    "## Demo 2: Multi-DataFrame Analysis\n",
    "\n",
    "When working with multiple related DataFrames, sPyTial shines by showing structural relationships that traditional tools miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadb57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create related DataFrames - a common real-world scenario\n",
    "\n",
    "# Projects DataFrame\n",
    "projects_df = pd.DataFrame({\n",
    "    'project_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'project_name': ['WebApp Redesign', 'Mobile App', 'Data Migration', 'API Development', 'Security Audit'],\n",
    "    'budget': [50000, 75000, 30000, 60000, 40000],\n",
    "    'department': ['Engineering', 'Engineering', 'Engineering', 'Engineering', 'Finance']\n",
    "})\n",
    "\n",
    "# Project assignments DataFrame  \n",
    "assignments_df = pd.DataFrame({\n",
    "    'assignment_id': range(1, 16),\n",
    "    'employee_id': np.random.choice(df['employee_id'].head(20), 15),  # Random assignments\n",
    "    'project_id': np.random.choice(projects_df['project_id'], 15),\n",
    "    'role': np.random.choice(['Developer', 'Designer', 'Manager', 'Analyst'], 15),\n",
    "    'allocation_pct': np.random.choice([25, 50, 75, 100], 15)\n",
    "})\n",
    "\n",
    "# Create a data analysis workspace\n",
    "analysis_workspace = {\n",
    "    'employees': df.head(10),  # Subset for clarity\n",
    "    'projects': projects_df,\n",
    "    'assignments': assignments_df,\n",
    "    'summary_stats': {\n",
    "        'total_employees': len(df),\n",
    "        'total_projects': len(projects_df),\n",
    "        'avg_salary': df['salary'].mean(),\n",
    "        'departments': df['department'].unique().tolist()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Multi-DataFrame Analysis Workspace:\")\n",
    "print(f\"- {len(analysis_workspace)} main components\")\n",
    "print(f\"- {len(analysis_workspace['employees'])} employees (subset)\")\n",
    "print(f\"- {len(analysis_workspace['projects'])} projects\")\n",
    "print(f\"- {len(analysis_workspace['assignments'])} assignments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d316a3",
   "metadata": {},
   "source": [
    "### Traditional Approach: Multiple Separate Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e8935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional approach: Show each DataFrame separately\n",
    "print(\"Traditional approach: Separate DataFrame views\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nüìä Projects DataFrame:\")\n",
    "print(projects_df)\n",
    "\n",
    "print(\"\\nüìä Assignments DataFrame:\")\n",
    "print(assignments_df.head())\n",
    "\n",
    "print(\"\\nüëé Problems with traditional approach:\")\n",
    "print(\"- Can't see relationships between DataFrames\")\n",
    "print(\"- No unified view of data architecture\") \n",
    "print(\"- Hard to understand overall data structure\")\n",
    "print(\"- Each view is isolated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2234567",
   "metadata": {},
   "source": [
    "### sPyTial Approach: Unified Structural View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c135c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sPyTial shows the relationships between all components\n",
    "print(\"sPyTial: Unified Analysis Workspace Structure\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "diagram(analysis_workspace, method=\"inline\")\n",
    "\n",
    "print(\"\\nüëç sPyTial advantages:\")\n",
    "print(\"- Shows relationships between DataFrames\")\n",
    "print(\"- Reveals data architecture patterns\")\n",
    "print(\"- Unified view of entire workspace\")\n",
    "print(\"- Spatial organization makes structure clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g3456789",
   "metadata": {},
   "source": [
    "## Demo 3: Enhanced DataFrame with Annotations\n",
    "\n",
    "sPyTial's real power comes from spatial annotations that add semantic meaning to your data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h4567890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an annotated version of our analysis workspace\n",
    "# Group related components and add visual cues\n",
    "\n",
    "annotated_workspace = group(field='data_tables', groupOn='structure_type')(\n",
    "    atomColor(selector='high_value', value='green')(\n",
    "        {\n",
    "            'data_tables': {\n",
    "                'employees': df.head(5),\n",
    "                'projects': projects_df,\n",
    "                'assignments': assignments_df\n",
    "            },\n",
    "            'metadata': {\n",
    "                'data_quality': 'high',\n",
    "                'last_updated': '2024-01-15',\n",
    "                'schema_version': '2.1'\n",
    "            },\n",
    "            'analytics': {\n",
    "                'total_budget': projects_df['budget'].sum(),\n",
    "                'avg_allocation': assignments_df['allocation_pct'].mean(),\n",
    "                'utilization_rate': 0.85\n",
    "            }\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Enhanced sPyTial Visualization with Annotations:\")\n",
    "diagram(annotated_workspace, method=\"inline\")\n",
    "\n",
    "print(\"\\n‚ú® Enhanced features:\")\n",
    "print(\"- Grouped related components (data_tables)\")\n",
    "print(\"- Color coding for important elements\")\n",
    "print(\"- Clear separation of data vs metadata vs analytics\")\n",
    "print(\"- Spatial organization reflects logical structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5678901",
   "metadata": {},
   "source": [
    "## Demo 4: Complex DataFrame Relationships\n",
    "\n",
    "For complex data analysis scenarios, sPyTial helps visualize intricate relationships that would be impossible to understand with traditional tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j6789012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complex data analysis pipeline\n",
    "pipeline_data = {\n",
    "    'raw_data': {\n",
    "        'source_employees': df,\n",
    "        'source_projects': projects_df\n",
    "    },\n",
    "    'processed_data': {\n",
    "        'employee_summary': df.groupby('department')['salary'].agg(['mean', 'count']).reset_index(),\n",
    "        'project_budget_analysis': projects_df.groupby('department')['budget'].sum().reset_index()\n",
    "    },\n",
    "    'results': {\n",
    "        'department_efficiency': pd.merge(\n",
    "            df.groupby('department')['performance_score'].mean().reset_index(),\n",
    "            projects_df.groupby('department')['budget'].sum().reset_index(),\n",
    "            on='department'\n",
    "        ),\n",
    "        'insights': {\n",
    "            'highest_paid_dept': df.groupby('department')['salary'].mean().idxmax(),\n",
    "            'most_projects_dept': projects_df['department'].value_counts().index[0],\n",
    "            'correlation_perf_budget': 0.67  # Simulated correlation\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Complex Data Pipeline Structure:\")\n",
    "diagram(pipeline_data, method=\"inline\")\n",
    "\n",
    "print(\"\\nüîç What sPyTial reveals:\")\n",
    "print(\"- Data flow from raw ‚Üí processed ‚Üí results\")\n",
    "print(\"- Relationships between different analysis stages\")\n",
    "print(\"- Structure of complex analytical workflows\")\n",
    "print(\"- How DataFrames transform through the pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k7890123",
   "metadata": {},
   "source": [
    "## Summary: Why sPyTial Beats Traditional Pandas Visualization\n",
    "\n",
    "| Traditional Approach | sPyTial Approach |\n",
    "|---------------------|------------------|\n",
    "| Shows **what** data looks like | Shows **how** data is structured |\n",
    "| Statistical patterns | Architectural patterns |\n",
    "| Isolated views | Unified structural views |\n",
    "| Data content focus | Data relationship focus |\n",
    "| Good for analysis | Good for understanding |\n",
    "\n",
    "### When to Use sPyTial:\n",
    "\n",
    "‚úÖ **Understanding DataFrame structure**  \n",
    "‚úÖ **Debugging complex data pipelines**  \n",
    "‚úÖ **Documenting data architecture**  \n",
    "‚úÖ **Teaching pandas concepts**  \n",
    "‚úÖ **Exploring multi-DataFrame relationships**  \n",
    "‚úÖ **Code reviews involving data structures**  \n",
    "\n",
    "### When to Use Traditional Tools:\n",
    "\n",
    "üìä **Statistical analysis**  \n",
    "üìä **Pattern discovery in data values**  \n",
    "üìä **Publication-ready charts**  \n",
    "üìä **Time series analysis**  \n",
    "\n",
    "**The key insight**: sPyTial and traditional visualization are *complementary*. Use traditional tools to understand your data values, use sPyTial to understand your data structure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}